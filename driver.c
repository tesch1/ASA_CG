/* We illustrate the operation of the code using the problem

        min \sum_{i=1}^n  exp (x [i]) - sqrt (i)*x [i] ;
        subject to 0 <= x <= 1

   We solve the problem 3 times using different parameter setting.
   On a linux workstation, the final statistics generated by driver
   were as follows:

Final convergence status = 0
Convergence tolerance for gradient satisfied
projected gradient max norm:  2.618104e-10
function value:              -4.011035e+02

Total cg  iterations:                    8
Total cg  function evaluations:          9
Total cg  gradient evaluations:         15
Total cbb iterations:                    3
Total cbb function evaluations:          4
Total cbb gradient evaluations:          4
------------------------------------------
Total function evaluations:             13
Total gradient evaluations:             19
==========================================

The principal change in Version3.0 is to update the conjugate
gradient routine to CG_DESCENT 6.0. Note that the objective
structure also contains a pointer to the array of free indices */

#include <math.h>
#include "asa_user.h" /* needed by the program which calls asa_cg*/

/* prototypes for the function and gradient evaluation routines */
double myvalue
(
    asa_objective *asa
) ;

void mygrad
(
    asa_objective *asa
) ;

double myvalgrad
(
    asa_objective *asa
) ;

int main (void)
{
    double *x, *lo, *hi ;
    ASAINT i, n ;

    /* if you want to change parameter value, you need the following: */
    asacg_parm cgParm ;
    asa_parm asaParm ;

    /* allocate arrays for problem solution and bounds */
    n = 100 ; /* problem dimension */
    x  = (double *) malloc (n*sizeof (double)) ;
    lo = (double *) malloc (n*sizeof (double)) ;
    hi = (double *) malloc (n*sizeof (double)) ;
    for (i = 0; i < n; i++) lo [i] = (double) 0 ;
    for (i = 0; i < n; i++) hi [i] = (double) 1 ;

    /* if you want to change parameter value, initialize strucs with default */
    asa_cg_default (&cgParm) ;
    asa_default (&asaParm) ;

    /* if you want to change parameters, change them here: */
    cgParm.PrintParms = TRUE ;
    cgParm.PrintLevel = 0 ;
    asaParm.PrintParms = TRUE ;
    asaParm.PrintLevel = 0 ;

    /* starting guess */
    for (i = 0; i < n; i++) x [i] = 1 ;

    /* run the code */
    asa_cg (x, lo, hi, n, NULL, &cgParm, &asaParm,
                     1.e-8, myvalue, mygrad, myvalgrad, NULL, NULL) ;

    /* if no change in parameters, you could replace Parm arguments by NULL*/
    for (i = 0; i < n; i++) x [i] = 1 ; /* starting guess */
    asa_cg (x, lo, hi, n, NULL, NULL, NULL,
                     1.e-8, myvalue, mygrad, myvalgrad, NULL, NULL) ;

    /* with some loss of efficiency, you could omit the valgrad routine */
    for (i = 0; i < n; i++) x [i] = 1 ; /* starting guess */
    asa_cg (x, lo, hi, n, NULL, NULL, NULL, 1.e-8, myvalue, mygrad, NULL,
            NULL, NULL);

    free (x) ;
    free (lo) ;
    free (hi) ;
}

double myvalue /* evaluate the objective function */
(
    asa_objective *asa
)
{
    double f, t, *x ;
    ASAINT i, n ;
    x = asa->x ;
    n = asa->n ;
    f = 0. ;
    for (i = 0; i < n; i++)
    {
        t = i + 1 ;
        t = sqrt (t) ;
        f += exp (x [i]) - t*x [i] ;
    }
    return (f) ;
}

void mygrad /* evaluate the gradient of the objective function */
(
    asa_objective *asa
)
{
    double t, *g, *x ;
    ASAINT i, n ;
    x = asa->x ;
    g = asa->g ;
    n = asa->n ;
    for (i = 0; i < n; i++)
    {
        t = i + 1 ;
        t = sqrt (t) ;
        g [i] = exp (x [i]) -  t ;
    }
    return ;
}

double myvalgrad /* value and gradient of the objective function */
(
    asa_objective *asa
)
{
    double f, xi, t, *g, *x ;
    ASAINT i, n ;
    x = asa->x ;
    g = asa->g ;
    n = asa->n ;
    f = 0 ;
    for (i = 0; i < n; i++)
    {
        t = i + 1 ;
        t = sqrt (t) ;
        xi = x [i] ;
        f += exp (xi) - t*xi ;
        g [i] = exp (xi) -  t ;
    }
    return (f) ;
}
